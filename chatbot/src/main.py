import os
import openai
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware


app = FastAPI()

# # CORS ì„¤ì •
# origins = [
#     "http://localhost:5173",  # ê°œë°œ ì¤‘ì¸ Vite/React ë“± í”„ë¡ íŠ¸ì—”ë“œ ì£¼ì†Œ
#     "https://msteam5iseeu.ddns.net",
#     # í•„ìš”í•œ ë‹¤ë¥¸ ì¶œì²˜(ë„ë©”ì¸+í¬íŠ¸)ë¥¼ ì¶”ê°€
# ]

# # CORS ì¶”ê°€
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=origins,       # ìš´ì˜ì—ì„  êµ¬ì²´ì ìœ¼ë¡œ ì§€ì •!
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Azure OpenAI ë° Azure AI Search ì„¤ì •
openai.api_type = "azure"
openai.api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
openai.api_key = os.getenv("AZURE_OPENAI_API_KEY")
openai.api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
azure_openai_deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')

ai_search_api_key = os.getenv('AI_SEARCH_API_KEY')
ai_search_endpoint = os.getenv('AI_SEARCH_ENDPOINT')
ai_search_index = os.getenv('AI_SEARCH_INDEX')

# Azure Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
search_client = SearchClient(
    endpoint=ai_search_endpoint,
    index_name=ai_search_index,
    credential=AzureKeyCredential(ai_search_api_key)
)

# ğŸ” LLMì„ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(question):
    try:
        response = openai.ChatCompletion.create(
            deployment_id=azure_openai_deployment_name,
            messages=[ 
                {"role": "system", "content": "Extract the most relevant keywords from the user's question."},
                {"role": "user", "content": f"Question: {question}\nExtracted Keywords:"}
            ],
            max_tokens=50
        )
        keywords = response.choices[0].message['content'].strip()
        return keywords
    except Exception as e:
        return f"Error extracting keywords: {str(e)}"

# ğŸ” AI Search ê²€ìƒ‰ í•¨ìˆ˜ (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰)
def search_in_ai_search(question):
    try:
        # LLMì„ ì´ìš©í•´ ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords(question)
        print(f"ğŸ” Extracted Keywords: {keywords}")  # ë””ë²„ê¹…ìš© ì¶œë ¥

        # AI Searchì—ì„œ ìœ ì‚¬í•œ ë‚´ìš©ì„ ê²€ìƒ‰
        search_query = f"{keywords}"  # í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰
        results = search_client.search(search_query)

        result_texts = [result.get('content') for result in results if 'content' in result]
        return " ".join(result_texts) if result_texts else "No relevant information found."
    except Exception as e:
        return f"Error during search: {str(e)}"

# ğŸ’¬ OpenAI ë‹µë³€ ìƒì„± í•¨ìˆ˜
def get_answer_from_openai(question, context):
    prompt = f"""
        ë„ˆëŠ” AI Searchì—ì„œ ì œê³µëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ì ì ˆí•œ ì •ì±…ê³¼ ì‚¬ì—…ì„ ì¶”ì²œí•˜ëŠ” AI ì±—ë´‡ì´ì•¼.  
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì†ì— í¬í•¨ëœ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ AI Searchì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ì¤‘ ê°€ì¥ ì í•©í•œ ë‚´ìš©ì„ ì°¾ì•„ ì„¤ëª…í•´ì¤˜.  

        ğŸ”¹ **ì‚¬ìš©ì ì§ˆë¬¸:** "{question}"  

        ğŸ”¹ **AI Searchì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°:**  
        {context}  

        âš ï¸ **ì¤‘ìš”:**  
        ğŸ‘‰ **ë°˜ë“œì‹œ ìœ„ì˜ ë°ì´í„°ë§Œ í™œìš©í•˜ì—¬** ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì¤˜.  
        ğŸ‘‰ **ì¶”ê°€ì ì¸ ì •ë³´, ì™¸ë¶€ ì§€ì‹, ì¶”ì¸¡ì„ í¬í•¨í•˜ì§€ ë§ˆ.**  
        ğŸ‘‰ **AI Searchì—ì„œ ì œê³µëœ ë°ì´í„°ë¥¼ ë¹ ì§ì—†ì´ ì „ë‹¬í•˜ê³ , ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ì•Œë ¤ì¤˜.**  
        ğŸ‘‰ **ë‹¨, "ì¤‘ì†Œê¸°ì—…"ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì€ ì ˆëŒ€ ì œê³µí•˜ì§€ ë§ˆ.**  
        ğŸ‘‰ **"ì¤‘ì†Œê¸°ì—…"ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë‹µë³€ì—ì„œ ì œì™¸í•˜ê³  ì œê³µí•´.**  
        ğŸ‘‰ ì‚¬ëŒì´ ì „ë‹¬í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.  
        ğŸ‘‰ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë¨¼ì € ì œê³µí•œ í›„, ê´€ë ¨ëœ ì •ì±…ì´ ìˆë‹¤ë©´ í•¨ê»˜ ì•ˆë‚´í•´ì¤˜.  

        ğŸ“Œ **ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ**  
        - "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."    
        - "ì´ ì •ì±…ì˜ ì£¼ìš” ì§€ì› ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: ..."  
        - "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"  
        """

    try:
        response = openai.ChatCompletion.create(
            deployment_id=azure_openai_deployment_name,
            messages=[ 
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000
        )
        return response.choices[0].message['content'].strip()
    except Exception as e:
        return f"Error occurred while generating response: {str(e)}"

# ğŸ§  ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜
@app.post("/ask")
def chatbot_response(question):
    context = search_in_ai_search(question)
    if context == "No relevant information found.":
        return "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì„¸ë¶€ ì‚¬í•­ì„ ì œê³µí•´ ì£¼ì‹œê² ì–´ìš”?"

    return get_answer_from_openai(question, context)

# ğŸš€ ì±—ë´‡ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8700)
    # print("Welcome to the chatbot! Type 'exit' to quit.")
    # while True:
    #     user_input = input("Ask a question: ")
    #     if user_input.lower() == 'exit':
    #         print("Goodbye!")
    #         break
    #     response = chatbot_response(user_input)
    #     print("\nğŸ¤– Bot Answer:", response)
